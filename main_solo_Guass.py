import distutils.util
import os
from argparse import ArgumentParser

import torch
import numpy as np
# from mlopt import Mlopt
from mloptSC_Guass import Mlopt
# from truss import Truss
from objectFunc_Guass import StepCoverage
from utils import unique, get_logger, Batch_evaluate


def main(args):
    os.makedirs(args.log_root, exist_ok=True)
    logger = get_logger(args)

    # truss = Truss(n_node=args.n_node, device='cuda')
    stepCover = StepCoverage(10)
    logger.info(f'number of variables: {100}')
    func = stepCover.get_function()
    # func = truss.get_function(inverse=True)
    batch_eval = Batch_evaluate()
    # inputs = torch.rand(100, 200)

    # a = np.load('./distList_100samples.npz')
    # b = a['arr_0']
    # inputs = torch.tensor(b/1e4, device='cuda:0', dtype=torch.float32)
    # inputs = torch.tensor(b, device='cuda:0', dtype=torch.float32)
    # inputs = torch.div(inputs.T, torch.sum(inputs, 1))
    # inputs = inputs.T

    # inputs = torch.load('./input100.pt')
    # inputs = torch.div(inputs.T, torch.sum(inputs, 1))
    # inputs = inputs.T
    inputs = torch.load('./input40_Guass.pt')
    # print(inputs)
    # print(inputs.sum())
    # print(torch.sum(inputs, 1))
    # print('---------input-sum----------')
    # truss.apply_discrete_thres(inputs)
    # inputs = unique(inputs, args.n_0)
    # outputsFile = np.load('./StepCover_100samples.npz')
    # # outputs_all = torch.tensor((outputsFile['arr_0']).reshape((100,3))/1e3, device='cuda:0', dtype=torch.float32)
    # outputs_all = torch.tensor((outputsFile['arr_0']).reshape((100,3)), device='cuda:0', dtype=torch.float32)
    # outputs = torch.sum(outputs_all, dim=1)
    # outputs = outputs.reshape(100,1)
    outputs = torch.load('./output40_Guass.pt')
    # print(outputs)
    net = Mlopt(inputs, outputs, device='cuda', node=args.node)
    n_greedy = max(int(args.n * args.ratio_greedy), 1)
    n_regular = args.n - n_greedy

    for i in range(args.n_iter):
        n_old = args.n_0 + args.n * i
        net.train(lr=0.001, batch_size=1024, n_epochs=1000, sample_interval=0, log_name=args.log_name, log_root=args.log_root, epc = i)  # train DNN
        print('----------train--------------')
        base, prediction, inputs_g, v_list = net.opt(n=args.n_ba, maxiter=args.maxiter, seed=None, is_min=False, topk=n_greedy * args.topk_coef,
                                                     low_mem=args.low_mem)  # perform BA optimization
        # print(inputs_g)
        # print(inputs_g.shape)
        # print('-----------inputs_g-----------')
        # print('----------opt--------------')
        inputs = unique(torch.cat([inputs, inputs_g]), n_old + n_greedy)  # generate new samples based on old & greedy (best ones from DNN)
        if n_regular > 0:
            inputs_r = stepCover.generate_input(n_regular * args.topk_coef, base)
            # inputs_r = truss.generate_input(n_regular * args.topk_coef, base)  # generate new samples for regular (by disturbance)
            inputs = unique(torch.cat([inputs, inputs_r]), n_old + args.n)
        # print(inputs.shape)
        # print(inputs)
        # print('------------inputs--------print(inputs.shape)----------')
        # compute objective values
        outputs_new = func(inputs[n_old:])

        print(outputs_new.shape)
        print(outputs_new.max())
        print('----------outputs_new----------------')
        outputs = torch.cat([outputs, outputs_new])

        # because of weird behavior of torch.unique (see more in unique function in utils.py), sometimes inputs and outputs are mismatched
        # temp_out = batch_eval(func, inputs)
        # try:
        #     if (temp_out != outputs).any():
        #         outputs = temp_out
        #         logger.error('adjust outputs')
        # except Exception as e:
        #     logger.error(e)
        #     outputs = temp_out
        #     logger.error('adjust outputs')

        net.update_data(inputs, outputs)

        ######## log ########

        logger.info(
            f'iteration: {i}, n_train: {n_old + args.n}, '
            f'current maximum: {outputs.max().item():.4f}, '
            f'prediction: {prediction.item():.4f}, truth: {outputs_new.max().item():.4f}'
        )

        if args.save_data_interval > 0 and (i % args.save_data_interval or i == args.n_iter - 1) == 0:
            torch.save(inputs, os.path.join(args.log_root, f"{args.log_name.split('.')[0]}_inputs.pt"))
            torch.save(outputs, os.path.join(args.log_root, f"{args.log_name.split('.')[0]}_outputs.pt"))


if __name__ == '__main__':
    parser = ArgumentParser()
    parser.add_argument("--n_iter", type=int, default=10, help="number of iterations/loops")
    parser.add_argument("--n", type=int, default=10, help="number of additional training data per iteration")
    parser.add_argument("--ratio_greedy", type=float, default=0.1,
                        help="ratio of greedy data (from BA), the rest (1-ratio_greedy) will be generated by disturbance")
    parser.add_argument("--n_0", type=int, default=100, help="number of initial training data")
    parser.add_argument("--log_root", type=str, default='./log_Guass', help="log file directory")
    parser.add_argument("--log_name", type=str, default='result_new_1124_Guass.log', help="log file name")
    parser.add_argument("--save_data_interval", type=int, default=1, help="save torch tensors every certain loops, 0 means no saving")
    parser.add_argument("--n_node", type=int, default=20, help="number of nodes in the truss")
    parser.add_argument("--node", type=int, default=1024, help="number of neurons in first DNN")
    parser.add_argument("--low_mem", type=distutils.util.strtobool, default=True,
                        help="whether to use low memory mode of BA (float16 instead of default float32)")
    parser.add_argument("--topk_coef", type=int, default=10,
                        help="when extracting data from BA/disturbance, more data (topk_coef*original) is needed in case some will be removed because they're repeated")
    parser.add_argument("--n_ba", type=int, default=500000, help="number of bats in BA")
    parser.add_argument("--maxiter", type=int, default=100, help="number of iterations in BA")
    args = parser.parse_args()
    main(args)
